\documentclass{article}
\usepackage{graphicx} % Required for inserting images
%\usepackage{algorithm}
%\usepackage{algpseudocode}
\usepackage{mathrsfs}

\title{Comparison of Frank-Wolfe Varients for White-Box Adversarial Attacks}
\author{Tanner Aaron Graves - 2073559\and Alessandro Pala - 2107800}
\date{June 2024}

\begin{document}

\maketitle

\section{Introduction}
What are Adversarial attacks\\
Problem statement\\
Type of Norms

\section{Algorithims}
\subsection{Frank-Wolfe}

\subsection{Pairwise Frank-Wolfe}
\subsection{Away-Step Frank-Wolfe}
\section{Results}
Introduce Datasets
\subsection{Momentum}
\subsection{Early-Stopping (Convergece Criterion)}
It is worth noting that Convergence Criterion For Frank-Wolfe is a somewhat imprecise surrogate for success in the context of adversarial attacks. For many examples, we find that Frank-Wolfe methods create successful attacks several iterations before convergence. We attribute this to an incorrect class probability being grater than the correct class being sufficient for success where convergence is reached when the new output class probability is maximized. 
We observe the convergence of the Frank-Wolfe gap 
\subsection{Stepsize}
The methods for stepsize where implemented: fixed, where $\gamma_t = 1$ for all $t$, linesearching which solves $\arg \min _\gamma f(x + \gamma d_t)$ where $\gamma \in (0,1]$, and decaying stepsize $\gamma_t = \frac{2}{t + 2}$.
\subsection{$\epsilon$ Choice}
Create plot showing how accurate attacks are with different $\epsilon$ constraints.
\section{Convergence Analysis}
The constrained nature of the Adversarial Attack problem means that the norm of the gradient $||\nabla_x f(x)||$ is not a sutible convergence criterion as boundry points need not have $0$ gradient. 
The Frank-Wolfe gap provides provides measure of both optimality and point feasibility. It is a measure of the maximum improvement over the current iteration $x_t$ within the constraints $C$ and defined
$$g(x_t) = \max_{x\in C} \langle x - x_t, -\nabla f(x_t)\rangle$$
We always have $g(x_t) \geq 0$ and its usefullness as a convergence criterion comes from $g(x_t) = 0$ iff $x_t$ is a stationary point. 
% See what the slides say about stationary points
For convex problems, we would have that the linear approximation $f(x_t) + \langle x_t - x, -\nabla f(x_t) \rangle \geq f(x)$. However, the loss of DNNs as commnly the subject of adversarial attacks, are highly non-convex, making this only true locally. This complicate the convergence of Frank-Wolfe in this application, but it is still gaurenteed.

\subsection{Frank-Wolfe}
\subsection{Pairwise Frank-Wolfe}
\subsection{Away-Step Frank-Wolfe}
\end{document}
